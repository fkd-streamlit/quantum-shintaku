# -*- coding: utf-8 -*-
""" 
Q-Quest é‡å­ç¥è¨— - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆStreamlit Community Cloudå‘ã‘ / æ­£å¼ç‰ˆ v2ï¼‰

- ç›´è¦³ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã§ã€Œ12ç¥ã€ã‚’æœ€åˆã«é¸æŠ â†’ ãã®ç¥ã‚’å›ºå®šã—ã¦QUBOã‚’è§£ã
- ãŠã¿ãã˜çŸ­æ–‡ã¯æ¯å›å¿…ãšè¡¨ç¤ºï¼ˆLLMæˆåŠŸæ™‚ã¯LLMæ–‡ã€å¤±æ•—æ™‚ã¯è‡ªç„¶ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–‡ï¼‰
- Optunaã§æœ€é©åŒ–ã®é€²æ—/å¯è¦–åŒ–ï¼ˆå±¥æ­´ç­‰ï¼‰ã‚’è¡¨ç¤º
- å›ºå®šç¥ã®ã‚‚ã¨ã§éšå±¤QUBOï¼ˆæ„Ÿè¦š8bitÃ—èª“é¡˜12=3072ï¼‰ã‚’å…¨åˆ—æŒ™ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼åœ°å½¢ã‚’å®‰å®šè¡¨ç¤º
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çƒä½“ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼è¿‘ã•ï¼‰å¯è¦–åŒ–
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒï¼šassets/images/characters/character_01.png ... character_12.png ã‚’è¡¨ç¤º
- Hugging Face APIã‚­ãƒ¼ã¯ st.secrets / ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å®‰å…¨ã«èª­ã¿è¾¼ã¿ï¼ˆã‚³ãƒ¼ãƒ‰ã‚„UIã«è¡¨ç¤ºã—ãªã„ï¼‰
"""

from __future__ import annotations

import io
import os
import re
import time
import json
import math
import random
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import requests

# ========================================================================================
# é‡å­ä¹±æ•°é–¢æ•°ï¼ˆæ–°è¦è¿½åŠ ï¼‰
# ========================================================================================

def get_quantum_random_bytes(n_bytes: int = 32) -> bytes:
    try:
        response = requests.get(
            f"https://qrng.anu.edu.au/API/jsonI.php?length={n_bytes}&type=uint8",
            timeout=3
        )
        if response.status_code == 200:
            data = response.json()
            if data.get('success'):
                return bytes(data['data'][:n_bytes])
    except Exception:
        pass
    return os.urandom(n_bytes)

def quantum_seed() -> int:
    qbytes = get_quantum_random_bytes(8)
    return int.from_bytes(qbytes, byteorder='big') % (2**32)

def quantum_float(low: float = 0.0, high: float = 1.0) -> float:
    qbytes = get_quantum_random_bytes(8)
    uint64 = int.from_bytes(qbytes, byteorder='big')
    norm = uint64 / (2**64 - 1)
    return low + (high - low) * norm

# -------------------------
# Optional deps
# -------------------------
try:
    from janome.tokenizer import Tokenizer
    JANOME_AVAILABLE = True
except Exception:
    JANOME_AVAILABLE = False
    Tokenizer = None

try:
    import optuna
    from optuna.visualization import (
        plot_optimization_history,
        plot_param_importances,
        plot_parallel_coordinate,
        plot_contour,
        plot_slice,
        plot_timeline,
    )
    OPTUNA_AVAILABLE = True
except Exception:
    OPTUNA_AVAILABLE = False
    optuna = None
    plot_optimization_history = None
    plot_param_importances = None
    plot_parallel_coordinate = None
    plot_contour = None
    plot_slice = None
    plot_timeline = None


# -------------------------
# Streamlit config
# -------------------------
st.set_page_config(
    page_title="Q-Quest é‡å­ç¥è¨—",
    page_icon="ğŸ”®",
    layout="wide",
    initial_sidebar_state="expanded",
)


# -------------------------
# Randomness control (session)
# -------------------------

def _get_session_seed() -> int:
    if "seed" not in st.session_state:
        st.session_state.seed = int(time.time() * 1000) % 1_000_000
    return int(st.session_state.seed)


def _rng() -> np.random.Generator:
    if "rng" not in st.session_state:
        st.session_state.rng = np.random.default_rng(_get_session_seed())
    return st.session_state.rng


# -------------------------
# Character images
# -------------------------

def get_character_image_path(god_id: int) -> Optional[str]:
    """assets/images/characters/character_01.png ... character_12.png"""
    fn = f"character_{god_id+1:02d}.png"
    path = os.path.join("assets", "images", "characters", fn)
    return path if os.path.exists(path) else None


# -------------------------
# String utilities (Excel)
# -------------------------

def _split_multi_text(cell_value: str) -> List[str]:
    if cell_value is None:
        return []
    s = str(cell_value).strip()
    if not s or s.lower() in ("nan", "none"):
        return []
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    parts: List[str] = []
    for chunk in s.split("\n\n"):
        parts.extend([p.strip() for p in chunk.split("\n") if p.strip()])
    return [p for p in parts if p]


def _parse_tagged_quote(line: str) -> Dict[str, object]:
    raw = (line or "").strip()
    if "::" in raw:
        tag_part, quote_part = raw.split("::", 1)
        tags = [t.strip() for t in tag_part.split(",") if t.strip()]
        quote = quote_part.strip()
        return {"text": quote, "tags": tags}
    return {"text": raw, "tags": []}


# -------------------------
# Default data (12 gods)
# -------------------------
TWELVE_GODS = [
    {"id": 0, "name": "ç§‹è‘‰ä¸‰å°ºåŠ", "name_en": "Akiba Sanjakubo", "attribute": "ç«", "emoji": "ğŸ”¥",
     "vows": {"vow01": -0.4, "vow02": 0.2, "vow03": -0.2, "vow04": 0.0, "vow05": 0.0,
              "vow06": 0.0, "vow07": 0.0, "vow08": -0.4, "vow09": 0.0, "vow10": 0.0,
              "vow11": 0.0, "vow12": -0.2},
     "roles": {"stillness": 0.0, "flow": -0.2, "ma": 0.0, "sincerity": -0.4},
     "maxim": "å‹¢ã„MAX: æƒ…ç†±çš„ãªç­†è‡´ã«é™è‡¨ã€‚",
     "description": "ç§‹è‘‰åŸã®å®ˆè­·ç¥ã€‚ç«ä¼ã›=ã€Œç‚ä¸Šå›é¿ã€ã®ç¥ã€‚"},
    {"id": 1, "name": "çœŸç©ºç®¡å¤§å°†è»", "name_en": "Vacuum Tube General", "attribute": "é›»", "emoji": "âš¡",
     "vows": {"vow01": -0.2, "vow02": 0.2, "vow03": 0.0, "vow04": -0.4, "vow05": -0.2,
              "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
              "vow11": 0.0, "vow12": -0.4},
     "roles": {"stillness": 0.0, "flow": -0.4, "ma": 0.0, "sincerity": -0.2},
     "maxim": "ç·šã®å¤ªã•: åŠ›å¼·ãã€å¤ªã„ç·šã«åå¿œã€‚",
     "description": "ç§‹è‘‰åŸã®åŸç‚¹ã€‚å¢—å¹…=ã€Œæ‰èƒ½é–‹èŠ±ã€ã®ç¥ã€‚"},
    {"id": 2, "name": "LEDå¼è²¡å¤©", "name_en": "LED Benzaiten", "attribute": "å…‰", "emoji": "ğŸ’¡",
     "vows": {"vow01": 0.0, "vow02": 0.2, "vow03": 0.0, "vow04": -0.4, "vow05": 0.0,
              "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": -0.4, "vow10": 0.0,
              "vow11": -0.2, "vow12": -0.2},
     "roles": {"stillness": 0.0, "flow": -0.4, "ma": -0.2, "sincerity": 0.0},
     "maxim": "ä¸¸ã¿: è¯ã‚„ã‹ã§æ›²ç·šçš„ãªç­†è·¡ã€‚",
     "description": "ã‚¤ãƒ«ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨ç™ºå…‰ã€‚ã€Œè‡ªå·±è¡¨ç¾ã€ã®ç¥ã€‚"},
    {"id": 3, "name": "ç£æ°—è¨˜éŒ²é»’é¾", "name_en": "Magnetic Recording Black Dragon", "attribute": "ç£", "emoji": "ğŸ‰",
     "vows": {"vow01": 0.0, "vow02": 0.0, "vow03": -0.4, "vow04": 0.0, "vow05": -0.2,
              "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": 0.0, "vow10": -0.4,
              "vow11": -0.2, "vow12": 0.2},
     "roles": {"stillness": -0.2, "flow": 0.0, "ma": 0.0, "sincerity": -0.4},
     "maxim": "ç·»å¯†ã•: ç´°ã‹ãä¸å¯§ãªæ›¸ãè¾¼ã¿ã€‚",
     "description": "HDDã‚„ãƒ†ãƒ¼ãƒ—ã€‚è¨˜æ†¶=ã€Œæ¸©æ•…çŸ¥æ–°ã€ã®å®ˆè­·é¾ã€‚"},
    {"id": 4, "name": "ç„¡ç·šå‚å—è¦³éŸ³", "name_en": "Wireless Interception Kannon", "attribute": "æ³¢", "emoji": "ğŸ“¡",
     "vows": {"vow01": -0.4, "vow02": 0.2, "vow03": 0.0, "vow04": -0.2, "vow05": -0.4,
              "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
              "vow11": 0.0, "vow12": -0.2},
     "roles": {"stillness": 0.0, "flow": -0.4, "ma": -0.2, "sincerity": 0.0},
     "maxim": "ã‚†ã‚‰ã: éœ‡ãˆã‚„è¿·ã„ãŒã‚ã‚‹ç­†è·¡ã«å¯„ã‚Šæ·»ã†ã€‚",
     "description": "é›»æ³¢ã¨é€šä¿¡ã€‚ç¸çµã³=ã€Œãƒãƒƒãƒãƒ³ã‚°ã€ã®ç¥ã€‚"},
    {"id": 5, "name": "åŸºæ¿æ›¼è¼ç¾…", "name_en": "Circuit Board Mandala", "attribute": "åŸº", "emoji": "ğŸ”Œ",
     "vows": {"vow01": 0.0, "vow02": -0.2, "vow03": 0.0, "vow04": 0.0, "vow05": 0.0,
              "vow06": -0.4, "vow07": -0.4, "vow08": 0.0, "vow09": 0.2, "vow10": -0.2,
              "vow11": 0.0, "vow12": 0.0},
     "roles": {"stillness": -0.4, "flow": 0.0, "ma": 0.0, "sincerity": -0.2},
     "maxim": "ç›´ç·šçš„: è¿·ã„ã®ãªã„ã€ã‚«ã‚¯ã‚«ã‚¯ã—ãŸç·šã€‚",
     "description": "å›è·¯è¨­è¨ˆã€‚ç§©åº=ã€Œè«–ç†çš„æ€è€ƒã€ã®ç¥ã€‚"},
    {"id": 6, "name": "çµ¶å¯¾é›¶åº¦æ˜ç‹", "name_en": "Absolute Zero Myo-o", "attribute": "å†·", "emoji": "â„ï¸",
     "vows": {"vow01": 0.0, "vow02": -0.4, "vow03": -0.2, "vow04": 0.0, "vow05": 0.0,
              "vow06": 0.0, "vow07": -0.4, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
              "vow11": -0.2, "vow12": 0.2},
     "roles": {"stillness": -0.4, "flow": 0.0, "ma": -0.2, "sincerity": 0.0},
     "maxim": "ç­†åœ§å¼±ã‚: ã‚¯ãƒ¼ãƒ«ã§æ·¡ã€…ã¨ã—ãŸç­†è·¡ã€‚",
     "description": "å†·å´ãƒ•ã‚¡ãƒ³ãƒ»è¶…é›»å°ã€‚å†·é™=ã€Œæ²ˆç€å†·é™ã€ã®ç¥ã€‚"},
    {"id": 7, "name": "ã‚¸ãƒ£ãƒ³ã‚¯å†ç”Ÿç«¥å­", "name_en": "Junk Regeneration Child", "attribute": "å£Š", "emoji": "ğŸ”§",
     "vows": {"vow01": -0.2, "vow02": 0.0, "vow03": 0.0, "vow04": -0.2, "vow05": 0.0,
              "vow06": 0.0, "vow07": 0.2, "vow08": -0.4, "vow09": 0.0, "vow10": 0.0,
              "vow11": 0.0, "vow12": -0.4},
     "roles": {"stillness": 0.0, "flow": -0.4, "ma": 0.0, "sincerity": -0.2},
     "maxim": "ã‹ã™ã‚Œ: è’ã€…ã—ã„ã€ã¾ãŸã¯æ ã‚ŒãŸç·šã€‚",
     "description": "ç§‹è‘‰åŸã®ã‚¸ãƒ£ãƒ³ã‚¯å“ã€‚å¾©æ´»=ã€Œå†èµ·ãƒ»ãƒªãƒˆãƒ²ã€ã®ç¥ã€‚"},
    {"id": 8, "name": "çœŸç©ºã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå¦‚æ¥", "name_en": "Vacuum Audio Nyorai", "attribute": "éŸ³", "emoji": "ğŸ§",
     "vows": {"vow01": 0.0, "vow02": 0.0, "vow03": 0.0, "vow04": -0.2, "vow05": -0.4,
              "vow06": 0.0, "vow07": 0.2, "vow08": 0.0, "vow09": -0.2, "vow10": 0.0,
              "vow11": -0.4, "vow12": 0.0},
     "roles": {"stillness": 0.0, "flow": -0.4, "ma": -0.2, "sincerity": 0.0},
     "maxim": "èª¿å’Œ: æ–‡å­—å…¨ä½“ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ã€‚",
     "description": "é«˜éŸ³è³ªãƒ»å…±é³´ã€‚ã€Œæœ¬è³ªã‚’è¦‹æ¥µã‚ã‚‹ã€ç¥ã€‚"},
    {"id": 9, "name": "ãƒãƒ³ãƒ€ä»˜ã‘çµã³ç¥", "name_en": "Soldering Connection Deity", "attribute": "çµ", "emoji": "ğŸ”—",
     "vows": {"vow01": 0.0, "vow02": -0.4, "vow03": -0.2, "vow04": 0.0, "vow05": -0.4,
              "vow06": 0.0, "vow07": -0.2, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
              "vow11": 0.0, "vow12": 0.2},
     "roles": {"stillness": -0.2, "flow": 0.0, "ma": -0.4, "sincerity": 0.0},
     "maxim": "ãƒˆãƒ¡ãƒ»ãƒãƒ: ç¹‹ãéƒ¨åˆ†ãŒã—ã£ã‹ã‚Šã—ã¦ã„ã‚‹ã€‚",
     "description": "æ¥ç‚¹ã¨çµåˆã€‚å”åŠ›=ã€Œãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã®ç¥ã€‚"},
    {"id": 10, "name": "å…‰é€Ÿé€šä¿¡éŸ‹é§„å¤©", "name_en": "Light-speed Communication Idaten", "attribute": "é€Ÿ", "emoji": "ğŸš€",
     "vows": {"vow01": 0.0, "vow02": 0.2, "vow03": 0.0, "vow04": -0.2, "vow05": -0.4,
              "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": -0.2, "vow10": 0.0,
              "vow11": 0.0, "vow12": -0.4},
     "roles": {"stillness": 0.0, "flow": -0.4, "ma": 0.0, "sincerity": -0.2},
     "maxim": "æ›¸ãé€Ÿåº¦: ã‚µãƒƒã¨çŸ­æ™‚é–“ã§æ›¸ã„ãŸç·šã€‚",
     "description": "5Gãƒ»å…‰å›ç·šã€‚çˆ†é€Ÿ=ã€Œå³æ–­å³æ±ºã€ã®ç¥ã€‚"},
    {"id": 11, "name": "åŠå°ä½“æ–‡æ®Š", "name_en": "Semiconductor Manjushri", "attribute": "æ™º", "emoji": "ğŸ§ ",
     "vows": {"vow01": 0.0, "vow02": 0.0, "vow03": -0.2, "vow04": 0.0, "vow05": 0.0,
              "vow06": -0.4, "vow07": -0.2, "vow08": 0.0, "vow09": 0.0, "vow10": -0.4,
              "vow11": 0.0, "vow12": 0.2},
     "roles": {"stillness": -0.4, "flow": 0.0, "ma": 0.0, "sincerity": -0.2},
     "maxim": "è¦å‰‡æ€§: ç­‰é–“éš”ã§æ•´ç†ã•ã‚ŒãŸç­†è·¡ã€‚",
     "description": "CPUãƒ»AIã€‚è¨ˆç®—=ã€Œåˆæ ¼ãƒ»çŸ¥ç•¥ã€ã®ç¥ã€‚"},
]

SEASONS = ["è–„æ°·", "ç«‹æ˜¥", "æ˜¥éœ", "è‹¥è‘‰", "å¤•ç«‹", "ç§‹å£°", "æœ¨æ¯ã‚‰ã—", "é›ªæ˜ã‚Š"]
MAXIM_SOURCES = {g["maxim"]: {"source": g["name"], "origin": g["name_en"], "reference": g["description"]} for g in TWELVE_GODS}

NEXT_STEPS_BY_MOOD = {
    "fatigue": ["ä¸€ã¤ã ã‘ã€ä»Šæ—¥ã‚„ã‚‹ã“ã¨ã‚’æ¸›ã‚‰ã—ãªã•ã„ã€‚", "é å›ã‚Šã‚’é¸ã³ãªã•ã„ã€‚ç­”ãˆã¯é“ã®é€”ä¸­ã«ã‚ã‚‹ã€‚", "æ±ºã‚ãªãã¦ã‚ˆã„ã€‚ä¿ç•™ã¯ã€ç«‹æ´¾ãªé¸æŠã§ã‚ã‚‹ã€‚"],
    "anxiety": ["è©±ã™ãªã‚‰ã€çµè«–ã€ã‚ˆã‚Šã€æ°—é…ã€ã‚’æ¸¡ã—ãªã•ã„ã€‚", "å¢ƒç•Œï¼ˆã—ãã„ï¼‰ã‚’è¶Šãˆã‚‹ã®ã¯ã€é™ã‹ãªä¸€æ­©ã§ã‚ˆã„ã€‚", "æ°´ã®ã‚ˆã†ã«æµã‚Œã‚‹ãŒã¾ã¾ã«ã€‚å½¢ã«ã“ã ã‚ã‚‰ãªã„ã€‚"],
    "curiosity": ["åƒé‡Œã®é“ã‚‚ä¸€æ­©ã‹ã‚‰ã€‚æ­©ã¿ã‚’æ­¢ã‚ãšã€ç¶šã‘ã‚‹ã“ã¨ã«æ„å‘³ãŒã‚ã‚‹ã€‚", "æˆé•·ã¯éç¨‹ã«ã‚ã‚Šã€‚ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚", "æŒ‘æˆ¦ã™ã‚‹å‹‡æ°—ã“ããŒã€æœªæ¥ã‚’é–‹ãéµã§ã‚ã‚‹ã€‚"],
    "loneliness": ["ä¸€æœŸä¸€ä¼šã€‚ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚", "äººã®å¿ƒã«å¯„ã‚Šæ·»ã†ã€‚ãã‚ŒãŒçœŸã®å¼·ã•ã§ã‚ã‚‹ã€‚", "çµ†ã¯è¦‹ãˆãªãã¦ã‚‚ã€ãã“ã«ã‚ã‚‹ã€‚"],
    "decisiveness": ["æ±ºã‚ãªãã¦ã‚ˆã„ã€‚ä¿ç•™ã¯ã€ç«‹æ´¾ãªé¸æŠã§ã‚ã‚‹ã€‚", "å·±ã«èª å®Ÿã§ã‚ã‚‹ã“ã¨ã€‚ãã‚ŒãŒè‡ªç”±ã¸ã®é“ã§ã‚ã‚‹ã€‚", "é“ãŒåˆ†ã‚Œã¦ã„ãŸã‚‰ã€å¿µãŒãªã„æ–¹ã¸è¡Œã‘ã€‚"],
    "default": ["ä¸€ã¤ã ã‘ã€ä»Šæ—¥ã‚„ã‚‹ã“ã¨ã‚’æ¸›ã‚‰ã—ãªã•ã„ã€‚", "é å›ã‚Šã‚’é¸ã³ãªã•ã„ã€‚ç­”ãˆã¯é“ã®é€”ä¸­ã«ã‚ã‚‹ã€‚", "è©±ã™ãªã‚‰ã€çµè«–ã€ã‚ˆã‚Šã€æ°—é…ã€ã‚’æ¸¡ã—ãªã•ã„ã€‚", "æ±ºã‚ãªãã¦ã‚ˆã„ã€‚ä¿ç•™ã¯ã€ç«‹æ´¾ãªé¸æŠã§ã‚ã‚‹ã€‚", "å¢ƒç•Œï¼ˆã—ãã„ï¼‰ã‚’è¶Šãˆã‚‹ã®ã¯ã€é™ã‹ãªä¸€æ­©ã§ã‚ˆã„ã€‚"],
}

GLOBAL_WORDS_DATABASE = [
    "ä¸–ç•Œå¹³å’Œ", "è²¢çŒ®", "æˆé•·", "å­¦ã³", "æŒ‘æˆ¦", "å¤¢", "å¸Œæœ›", "æœªæ¥",
    "æ„Ÿè¬", "æ„›", "å¹¸ã›", "å–œã³", "å®‰å¿ƒ", "å……å®Ÿ", "æº€è¶³", "å¹³å’Œ",
    "åŠªåŠ›", "ç¶™ç¶š", "å¿è€", "èª å®Ÿ", "æ­£ç›´", "å„ªã—ã•", "æ€ã„ã‚„ã‚Š", "å…±æ„Ÿ",
    "èª¿å’Œ", "ãƒãƒ©ãƒ³ã‚¹", "è‡ªç„¶", "ç¾", "çœŸå®Ÿ", "è‡ªç”±", "æ­£ç¾©", "é“",
    "çµ†", "ã¤ãªãŒã‚Š", "å®¶æ—", "å‹äºº", "ä»²é–“", "ä¿¡é ¼", "å°Šæ•¬", "å”åŠ›", "å¤«å©¦", "ç”Ÿæ´»", "å††æº€",
    "ä»Š", "ç¬é–“", "éç¨‹", "å¤‰åŒ–", "é€²åŒ–", "ç™ºå±•", "å¾ªç’°", "æµã‚Œ",
    "é™ã‘ã•", "é›†ä¸­", "è¦šæ‚Ÿ", "æ±ºæ„", "å‹‡æ°—", "å¼·ã•", "æŸ”è»Ÿæ€§", "å¯›å®¹",
]

FAMOUS_QUOTES = [
    {"keywords": ["å¹³å’Œ", "ä¸–ç•Œ", "è²¢çŒ®", "å¸Œæœ›"], "quote": "é›ªã®ä¸‹ã§ç¨®ã¯æ˜¥ã‚’å¾…ã£ã¦ã„ã‚‹ã€‚ç„¦ã‚‹ã¹ã‹ã‚‰ãšã€æ™‚æº€ã¡ã‚‹ã‚’å¾…ã¦ã€‚", "source": "æ—¥æœ¬ã®å¤èªãƒ»ã“ã¨ã‚ã–", "origin": "è‡ªç„¶ã®æ‘‚ç†", "reference": "å¿è€"},
    {"keywords": ["æˆé•·", "åŠªåŠ›", "ç¶™ç¶š", "æŒ‘æˆ¦"], "quote": "åƒé‡Œã®é“ã‚‚ä¸€æ­©ã‹ã‚‰ã€‚æ­©ã¿ã‚’æ­¢ã‚ãšã€ç¶šã‘ã‚‹ã“ã¨ã«æ„å‘³ãŒã‚ã‚‹ã€‚", "source": "è€å­ã€é“å¾³çµŒã€", "origin": "ç¬¬å…­åå››ç« ", "reference": "ä¸€æ­©"},
    {"keywords": ["æ„Ÿè¬", "æ„›", "çµ†", "ã¤ãªãŒã‚Š"], "quote": "ä¸€æœŸä¸€ä¼šã€‚ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚", "source": "èŒ¶é“ç²¾ç¥", "origin": "ä¸€æœŸä¸€ä¼š", "reference": "ç¸"},
]


# -------------------------
# Mood inference
# -------------------------

@dataclass
class Mood:
    fatigue: float
    anxiety: float
    curiosity: float
    loneliness: float
    decisiveness: float


KEYWORDS = {
    "fatigue": ["ç–²", "ã—ã‚“ã©", "çœ ", "ã ã‚‹", "æ¶ˆè€—", "é™ç•Œ", "ä½“èª¿", "é‡", "å‹•ã‘ãªã„"],
    "anxiety": ["ä¸å®‰", "ç„¦", "æ€–", "å¿ƒé…", "è¿·", "è½ã¡ç€ã‹", "ç·Šå¼µ", "æ°—ã«ãªã‚‹", "è‡ªä¿¡", "æŒã¦ãªã„", "å¤±æ•—", "é–“é•ã„", "å¦å®š", "æ‰¹åˆ¤"],
    "curiosity": ["ã‚„ã£ã¦ã¿", "èˆˆå‘³", "é¢ç™½", "å­¦ã³", "è©¦", "æŒ‘æˆ¦", "ãƒ¯ã‚¯ãƒ¯ã‚¯", "çŸ¥ã‚ŠãŸã„", "æ¢ç´¢", "æˆé•·", "å‘ä¸Š", "æ”¹å–„", "ç™ºå±•", "å‰é€²"],
    "loneliness": ["å­¤ç‹¬", "ä¸€äºº", "å¯‚", "èª°ã«ã‚‚", "åˆ†ã‹ã£ã¦", "è©±ã›", "å­¤ç«‹", "ç–å¤–"],
    "decisiveness": ["æ±ºã‚", "çµè«–", "é¸", "åˆ¤æ–­", "æ–­", "æ–¹é‡", "æœŸé™", "æ±ºæ–­", "èºŠèº‡", "ãŸã‚ã‚‰", "å„ªæŸ”ä¸æ–­"],
}


def score_from_text(text: str, keys: List[str]) -> float:
    s = 0.0
    tl = text.lower()
    for k in keys:
        matches = len(re.findall(re.escape(k.lower()), tl))
        if matches > 0:
            base = matches * 0.5
            if len(k) >= 3:
                base += 0.5
            if len(k) >= 4:
                base += 0.3
            s += base
    return float(s)


def infer_mood(text: str) -> Mood:
    t = (text or "").strip()
    if not t:
        return Mood(0.0, 0.0, 0.0, 0.0, 0.0)

    raw = {k: score_from_text(t, v) for k, v in KEYWORDS.items()}
    max_raw = max(raw.values()) if max(raw.values()) > 0 else 1.0

    def norm(x: float, scale: float) -> float:
        if x == 0.0:
            return 0.0
        relative = x / max_raw if max_raw > 0 else 1.0
        absolute = min(1.0, x / scale)
        combined = (relative * 0.6 + absolute * 0.4)
        return float(max(0.15, min(1.0, combined)))

    return Mood(
        fatigue=norm(raw["fatigue"], 1.2),
        anxiety=norm(raw["anxiety"], 1.0),
        curiosity=norm(raw["curiosity"], 1.3),
        loneliness=norm(raw["loneliness"], 1.2),
        decisiveness=norm(raw["decisiveness"], 1.1),
    )


def mood_to_sensation_vector(m: Mood, binary: bool = False, scale: float = 5.0) -> np.ndarray:
    x = np.zeros(8)
    x[0] = m.anxiety * (1.0 - m.decisiveness)
    x[1] = m.anxiety
    x[2] = (m.fatigue + m.loneliness) / 2.0
    x[3] = (m.loneliness + m.fatigue) / 2.0
    x[4] = (m.curiosity + m.decisiveness) / 2.0
    x[5] = (1.0 - m.loneliness) * m.curiosity
    x[6] = m.curiosity * m.decisiveness
    x[7] = m.fatigue * (1.0 - m.decisiveness)

    x = x * scale
    if binary:
        return (x >= 0.3 * scale).astype(float)
    return x


# -------------------------
# HF API key secure loading
# -------------------------

def get_hf_api_key() -> str:
    """st.secrets ã‹ã‚‰å–å¾—ï¼ˆCloudæ¨å¥¨ï¼‰ã€‚ç„¡ã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°ã€‚"""
    # st.secrets ã¯ç„¡ã„ã¨ä¾‹å¤–ã«ãªã‚‹å ´åˆãŒã‚ã‚‹ã®ã§å®‰å…¨ã«
    try:
        if "HUGGINGFACE_API_KEY" in st.secrets:
            return str(st.secrets["HUGGINGFACE_API_KEY"]).strip()
    except Exception:
        pass
    return os.getenv("HUGGINGFACE_API_KEY", "").strip()


# -------------------------
# Excel loading (optional)
# -------------------------
SENSE_TO_VOW_MATRIX: Optional[np.ndarray] = None
K_MATRIX: Optional[np.ndarray] = None
L_MATRIX: Optional[np.ndarray] = None
LOADED_GODS: Optional[List[Dict]] = None
MAXIMS_DATABASE: Optional[List[Dict]] = None


def rebuild_globals_from_gods(gods_list: List[Dict]) -> None:
    global MAXIM_SOURCES
    # sources: include maxims list
    sources: Dict[str, Dict] = {}
    for g in gods_list:
        if g.get("maxim"):
            sources[g["maxim"]] = {"source": g.get("name", "ç¥è¨—"), "origin": g.get("name_en", ""), "reference": g.get("description", "")}
        for item in g.get("maxims", []) or []:
            if isinstance(item, dict) and item.get("text"):
                t = item["text"].strip()
                if t:
                    sources[t] = {"source": g.get("name", "ç¥è¨—"), "origin": g.get("name_en", ""), "reference": g.get("description", "")}
    if sources:
        MAXIM_SOURCES = sources


def load_maxims_from_excel(maxim_file: io.BytesIO) -> List[Dict]:
    global MAXIMS_DATABASE
    maxim_file.seek(0)
    df = pd.read_excel(maxim_file, engine="openpyxl", header=0)
    out = []
    for _, row in df.iterrows():
        txt = str(row.get("æ ¼è¨€", "")).strip()
        src = str(row.get("å‡ºå…¸", "")).strip()
        if not txt or txt.lower() in ("nan", "none"):
            continue
        tags = []
        if "ã‚¿ã‚°" in df.columns:
            tag_str = str(row.get("ã‚¿ã‚°", "")).strip()
            if tag_str and tag_str.lower() not in ("nan", "none"):
                tags = [t.strip() for t in tag_str.split(",") if t.strip()]
        out.append({"text": txt, "source": src or "ä¼çµ±çš„ãªæ•™ãˆ", "tags": tags})
    MAXIMS_DATABASE = out
    return out


def load_sense_to_vow_matrix(sense_to_vow_file: io.BytesIO) -> np.ndarray:
    sense_to_vow_file.seek(0)
    df = pd.read_excel(sense_to_vow_file, engine="openpyxl", header=0, index_col=0).iloc[:8, :12]
    return df.values.astype(float)


def load_gods_from_separate_files(character_file: io.BytesIO, k_file: io.BytesIO, l_file: io.BytesIO) -> Tuple[List[Dict], np.ndarray, np.ndarray]:
    k_file.seek(0)
    df_k = pd.read_excel(k_file, engine="openpyxl", header=0, index_col=0).iloc[:12, :12]
    k_matrix = df_k.values.astype(float)

    l_file.seek(0)
    df_l = pd.read_excel(l_file, engine="openpyxl", header=0, index_col=0).iloc[:12, :4]
    l_matrix = df_l.values.astype(float)

    if character_file is not None:
        character_file.seek(0)
        df_g = pd.read_excel(character_file, engine="openpyxl")
    else:
        # fallback
        names = [n for n in df_k.index.tolist() if n in df_l.index.tolist()]
        df_g = pd.DataFrame({"ID": range(12), "åå‰": names, "åå‰(è‹±èª)": [f"God {i+1}" for i in range(12)],
                             "å±æ€§": [""] * 12, "çµµæ–‡å­—": ["ğŸ”®"] * 12, "èª¬æ˜": [""] * 12, "æ ¼è¨€": [""] * 12})

    gods_list: List[Dict] = []
    role_names = ["stillness", "flow", "ma", "sincerity"]
    for idx, row in df_g.iterrows():
        god_id = int(row.get("ID", idx))
        name = str(row.get("åå‰", "")).strip()
        name_en = str(row.get("åå‰(è‹±èª)", "")).strip()
        attr = str(row.get("å±æ€§", "")).strip()
        emoji = str(row.get("çµµæ–‡å­—", "ğŸ”®")).strip()
        desc = str(row.get("èª¬æ˜", "")).strip()

        maxim_cells: List[str] = []
        maxim_cells.extend(_split_multi_text(row.get("æ ¼è¨€", "")))
        for col in row.index:
            if isinstance(col, str) and col.startswith("æ ¼è¨€") and col != "æ ¼è¨€":
                maxim_cells.extend(_split_multi_text(row.get(col, "")))
        maxims_parsed = [_parse_tagged_quote(m) for m in maxim_cells if str(m).strip()]
        maxim = maxims_parsed[0]["text"] if maxims_parsed else str(row.get("æ ¼è¨€", "")).strip()

        vows = {}
        if name in df_k.index:
            ridx = df_k.index.get_loc(name)
            for j in range(12):
                vows[f"vow{j+1:02d}"] = float(k_matrix[ridx, j])
        else:
            for j in range(12):
                vows[f"vow{j+1:02d}"] = float(k_matrix[god_id, j])

        roles = {}
        if name in df_l.index:
            ridx = df_l.index.get_loc(name)
            for j, rn in enumerate(role_names):
                roles[rn] = float(l_matrix[ridx, j])
        else:
            for j, rn in enumerate(role_names):
                roles[rn] = float(l_matrix[god_id, j])

        gods_list.append({
            "id": god_id,
            "name": name,
            "name_en": name_en,
            "attribute": attr,
            "emoji": emoji,
            "vows": vows,
            "roles": roles,
            "maxim": maxim,
            "maxims": maxims_parsed,
            "description": desc,
        })

    return gods_list, k_matrix, l_matrix


def load_excel_config(character_file, maxim_file, sense_to_vow_file, k_file, l_file) -> bool:
    global SENSE_TO_VOW_MATRIX, K_MATRIX, L_MATRIX, LOADED_GODS, TWELVE_GODS
    try:
        if k_file is None or l_file is None:
            st.sidebar.error("kè¡Œåˆ—ã¨lè¡Œåˆ—ã¯å¿…é ˆã§ã™")
            return False
        gods_list, k_matrix, l_matrix = load_gods_from_separate_files(character_file, k_file, l_file)
        if sense_to_vow_file is not None:
            SENSE_TO_VOW_MATRIX = load_sense_to_vow_matrix(sense_to_vow_file)
        else:
            SENSE_TO_VOW_MATRIX = None
        K_MATRIX, L_MATRIX = k_matrix, l_matrix
        LOADED_GODS = gods_list
        TWELVE_GODS = gods_list
        rebuild_globals_from_gods(gods_list)
        if maxim_file is not None:
            load_maxims_from_excel(maxim_file)
        return True
    except Exception as e:
        st.sidebar.error(f"è¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return False


# -------------------------
# QUBO
# -------------------------

def qubo_energy(x: np.ndarray, Q: Dict[Tuple[int, int], float]) -> float:
    e = 0.0
    n = len(x)
    for i in range(n):
        e += Q.get((i, i), 0.0) * x[i]
    for i in range(n):
        for j in range(i + 1, n):
            e += Q.get((i, j), 0.0) * x[i] * x[j]
    return float(e)


def build_qubo_with_quantum_fluctuation(
    x_bin: np.ndarray,
    mood: Mood,
    K_MATRIX: np.ndarray,
    L_MATRIX: np.ndarray,
    SENSE_TO_VOW_MATRIX: Optional[np.ndarray] = None,
    lambda_v: float = 5.0,
    lambda_c: float = 5.0,
    quantum_noise_level: float = 0.6,
) -> Tuple[Dict[Tuple[int, int], float], Dict]:
    Q: Dict[Tuple[int, int], float] = {}
    n_sense, n_vows, n_chars = 8, 12, 12
    v_start, c_start = n_sense, n_sense + n_vows
    
    metadata = {
        "quantum_seed": quantum_seed(),
        "noise_injections": [],
        "energy_shifts": {}
    }
    
    # é‡å­çš„åŸºåº•ãƒã‚¤ã‚¢ã‚¹
    for i in range(32):
        quantum_bias = quantum_float(-0.3, 0.3) * quantum_noise_level
        Q[(i, i)] = Q.get((i, i), 0.0) + quantum_bias
        metadata["noise_injections"].append({"bit": i, "bias": quantum_bias})
    
    # æ„Ÿè¦šãƒ“ãƒƒãƒˆ
    x_cont = mood_to_sensation_vector(mood, binary=False, scale=5.0)
    for i in range(n_sense):
        if x_bin[i] > 0:
            strength = float(np.clip(x_cont[i] / 5.0, 0.0, 1.0))
            bias = -1.0 * strength + quantum_float(-0.2, 0.2) * quantum_noise_level
            Q[(i, i)] = Q.get((i, i), 0.0) + bias
    
    # èª“é¡˜ one-hot
    for j in range(n_vows):
        vj = v_start + j
        Q[(vj, vj)] = Q.get((vj, vj), 0.0) - 2.0 * lambda_v
        for k in range(j + 1, n_vows):
            vk = v_start + k
            Q[(vj, vk)] = Q.get((vj, vk), 0.0) + 2.0 * lambda_v
    
    # ç¥ one-hotï¼ˆâ˜…å›ºå®šãƒšãƒŠãƒ«ãƒ†ã‚£ãªã—â˜…ï¼‰
    for k in range(n_chars):
        ck = c_start + k
        Q[(ck, ck)] = Q.get((ck, ck), 0.0) - 2.0 * lambda_c
        for l in range(k + 1, n_chars):
            cl = c_start + l
            Q[(ck, cl)] = Q.get((ck, cl), 0.0) + 2.0 * lambda_c
    
    # æ„Ÿè¦š-èª“é¡˜
    if SENSE_TO_VOW_MATRIX is not None:
        for i in range(n_sense):
            if x_bin[i] > 0:
                strength = float(np.clip(x_cont[i] / 5.0, 0.0, 1.0))
                for j in range(n_vows):
                    coupling = float(SENSE_TO_VOW_MATRIX[i, j]) * strength
                    coupling *= (1.0 + quantum_float(-0.2, 0.2) * quantum_noise_level)
                    Q[(i, v_start + j)] = Q.get((i, v_start + j), 0.0) + coupling
    
    # èª“é¡˜-ç¥ï¼ˆâ˜…é‡å­æºã‚‰ãä»˜ãâ˜…ï¼‰
    for j in range(n_vows):
        for k in range(n_chars):
            coupling = float(K_MATRIX[k, j])
            coupling *= (1.0 + quantum_float(-0.15, 0.15) * quantum_noise_level)
            Q[(v_start + j, c_start + k)] = Q.get((v_start + j, c_start + k), 0.0) + coupling
            metadata["energy_shifts"][f"vow{j}_god{k}"] = coupling - K_MATRIX[k, j]
    
    # æ„Ÿè¦š-ç¥
    role_mapping = {0: 0, 1: 1, 2: 0, 3: 2, 4: 1, 5: 2, 6: 1, 7: 3}
    for i in range(n_sense):
        if x_bin[i] > 0:
            rc = role_mapping.get(i, 0)
            for k in range(n_chars):
                coupling = float(L_MATRIX[k, rc])
                coupling *= (1.0 + quantum_float(-0.1, 0.1) * quantum_noise_level)
                Q[(i, c_start + k)] = Q.get((i, c_start + k), 0.0) + coupling
    
    # çŸ›ç›¾
    if x_bin[0] > 0 and x_bin[4] > 0:
        penalty = 3.0 * (1.0 + quantum_float(-0.3, 0.3) * quantum_noise_level)
        Q[(0, 4)] = Q.get((0, 4), 0.0) + penalty
    if x_bin[1] > 0 and x_bin[7] > 0:
        penalty = 3.0 * (1.0 + quantum_float(-0.3, 0.3) * quantum_noise_level)
        Q[(1, 7)] = Q.get((1, 7), 0.0) + penalty
    
    return Q, metadata

def solve_exact_fixed_char(Q: Dict[Tuple[int, int], float], fixed_god_id: int) -> List[Tuple[float, np.ndarray]]:
    sols: List[Tuple[float, np.ndarray]] = []
    n = 32
    v_start, c_start = 8, 20
    for bits in range(256):
        sense = np.array([(bits >> i) & 1 for i in range(8)], dtype=int)
        for vow_idx in range(12):
            x = np.zeros(n, dtype=int)
            x[:8] = sense
            x[v_start + vow_idx] = 1
            x[c_start + fixed_god_id] = 1
            sols.append((qubo_energy(x, Q), x))
    sols.sort(key=lambda t: t[0])
    return sols

def calculate_quantum_temperature(mood: Mood) -> float:
    """æ°—åˆ†ã‹ã‚‰æœ€é©ãªæ¸©åº¦ï¼ˆæºã‚‰ãã®å¼·ã•ï¼‰ã‚’æ±ºå®š"""
    base_temp = 0.5
    temp = base_temp + 0.3 * mood.curiosity - 0.2 * mood.fatigue + 0.1 * mood.anxiety
    temp += quantum_float(-0.1, 0.1)
    return float(np.clip(temp, 0.2, 1.0))


def boltzmann_sample(
    solutions: List[Tuple[float, np.ndarray]],
    temperature: float = 0.5,
    use_quantum_random: bool = True
) -> Tuple[float, np.ndarray]:
    """Boltzmannåˆ†å¸ƒã«å¾“ã£ã¦è§£ã‚’ç¢ºç‡çš„ã«é¸æŠ"""
    if not solutions:
        raise ValueError("è§£ã®ãƒªã‚¹ãƒˆãŒç©ºã§ã™")
    if len(solutions) == 1:
        return solutions[0]
    
    energies = np.array([e for e, _ in solutions])
    E_min = energies.min()
    E_shifted = energies - E_min
    
    if temperature <= 0:
        temperature = 1e-6
    
    weights = np.exp(-E_shifted / temperature)
    probs = weights / weights.sum()
    
    if use_quantum_random:
        r = quantum_float(0.0, 1.0)
    else:
        r = np.random.random()
    
    cumsum = np.cumsum(probs)
    idx = np.searchsorted(cumsum, r)
    idx = min(idx, len(solutions) - 1)
    
    return solutions[idx]


def solve_exact_all_gods(Q: Dict[Tuple[int, int], float]) -> List[Tuple[float, np.ndarray]]:
    """å…¨ã¦ã®ç¥Ã—å…¨ã¦ã®èª“é¡˜ã‚’å…¨åˆ—æŒ™ï¼ˆå›ºå®šãªã—ï¼‰"""
    sols: List[Tuple[float, np.ndarray]] = []
    n = 32
    v_start, c_start = 8, 20
    
    # å…¨12ç¥ã‚’å¯¾è±¡ã«
    for god_id in range(12):
        for bits in range(256):  # æ„Ÿè¦š8bit = 256é€šã‚Š
            sense = np.array([(bits >> i) & 1 for i in range(8)], dtype=int)
            for vow_idx in range(12):  # èª“é¡˜12é€šã‚Š
                x = np.zeros(n, dtype=int)
                x[:8] = sense
                x[v_start + vow_idx] = 1
                x[c_start + god_id] = 1
                sols.append((qubo_energy(x, Q), x))
    
    sols.sort(key=lambda t: t[0])
    return sols

def solve_optuna_fixed_char(Q: Dict[Tuple[int, int], float], fixed_god_id: int, n_trials: int, progress_container=None):
    if not OPTUNA_AVAILABLE:
        return None
    sampler = optuna.samplers.TPESampler(seed=_get_session_seed())
    study = optuna.create_study(direction="minimize", sampler=sampler)

    def objective(trial: optuna.Trial):
        vow_idx = trial.suggest_int("vow_idx", 0, 11)
        x = np.zeros(32, dtype=int)
        x[8 + vow_idx] = 1
        x[20 + fixed_god_id] = 1
        for i in range(8):
            x[i] = trial.suggest_int(f"sense_{i}", 0, 1)
        return qubo_energy(x, Q)

    if progress_container is not None:
        with progress_container:
            bar = st.progress(0)
        for i in range(n_trials):
            study.optimize(objective, n_trials=1, show_progress_bar=False)
            with progress_container:
                bar.progress(int(((i + 1) / n_trials) * 100))
    else:
        study.optimize(objective, n_trials=n_trials)

    return study


# -------------------------
# Omikuji core
# -------------------------

def extract_keywords(text: str, top_n: int = 8) -> List[str]:
    if not text or not text.strip():
        return []
    t = text.strip()
    found: List[str] = []

    tl = t.lower()
    for kws in KEYWORDS.values():
        for kw in kws:
            if kw.lower() in tl and kw not in found:
                found.append(kw)

    tmp = t
    for w in sorted(GLOBAL_WORDS_DATABASE, key=len, reverse=True):
        if w in tmp and w not in found:
            found.append(w)
            tmp = tmp.replace(w, " ")

    chunks = re.findall(r"[ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ ]{2,8}", tmp)
    stop = {"ã“ã¨", "ã‚‚ã®", "ãŸã‚", "ãã‚Œ", "ã“ã‚Œ", "ã‚ˆã†", "ã§ã™", "ã¾ã™"}
    for c in chunks:
        if c not in stop and c not in found:
            found.append(c)

    if JANOME_AVAILABLE:
        try:
            tok = Tokenizer()
            for token in tok.tokenize(t):
                pos = token.part_of_speech.split(",")[0]
                if pos in ["åè©", "å‹•è©", "å½¢å®¹è©"]:
                    s = token.surface
                    if 2 <= len(s) <= 8 and s not in stop and s not in found:
                        found.append(s)
        except Exception:
            pass

    return list(dict.fromkeys(found))[:top_n]


def get_maxim_source(maxim: str) -> Dict:
    if maxim in MAXIM_SOURCES:
        return MAXIM_SOURCES[maxim]
    for q in FAMOUS_QUOTES:
        if q.get("quote") == maxim:
            return {"source": q.get("source", "å¼•ç”¨"), "origin": q.get("origin", ""), "reference": q.get("reference", "")}
    return {"source": "ä¼çµ±çš„ãªæ•™ãˆ", "origin": "å¤æ¥ã‚ˆã‚Šä¼ã‚ã‚‹æ™ºæ…§", "reference": ""}


def select_relevant_quote(keywords: List[str]) -> str:
    ks = set(keywords)
    scored = []
    for q in FAMOUS_QUOTES:
        score = len(ks & set(q["keywords"])) + float(_rng().uniform(-0.2, 0.2))
        scored.append((score, q["quote"]))
    scored.sort(key=lambda x: x[0], reverse=True)
    return scored[0][1] if scored else "ã‚ãªãŸã®è¦³æ¸¬ãŒã€ã“ã®ä¸–ç•Œç·šã‚’ç¢ºå®šã•ã›ã¾ã—ãŸã€‚"


def select_maxims_from_database(keywords: List[str], top_k: int = 3, exclude: Optional[List[str]] = None) -> List[Dict]:
    if not MAXIMS_DATABASE:
        return []
    exclude_set = set(exclude or [])
    keyset = set([k.lower() for k in keywords])

    scored = []
    for m in MAXIMS_DATABASE:
        txt = m.get("text", "")
        if not txt or txt in exclude_set:
            continue
        low = txt.lower()
        tags = [t.lower() for t in (m.get("tags") or [])]
        score = 0.0
        for kw in keyset:
            if kw in low:
                score += 5.0
            if any(kw in tg for tg in tags):
                score += 3.0
        if score > 0:
            scored.append((score, m))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [m for _, m in scored[:top_k]]


def select_picks_for_god(god: Dict, context_text: str, top_k: int = 3) -> List[str]:
    exclude = st.session_state.get("recent_maxims", [])[-10:]
    picks: List[str] = []

    god_maxims = []
    if god.get("maxims"):
        for it in god["maxims"]:
            if isinstance(it, dict) and it.get("text"):
                god_maxims.append(it["text"].strip())
    if not god_maxims and god.get("maxim"):
        god_maxims = [god["maxim"].strip()]

    for gm in god_maxims:
        if gm and gm not in picks and gm not in exclude:
            picks.append(gm)
        if len(picks) >= top_k:
            break

    kws = extract_keywords(context_text, top_n=8) if context_text else []
    if MAXIMS_DATABASE and kws and len(picks) < top_k:
        dbs = select_maxims_from_database(kws, top_k=top_k, exclude=exclude + picks)
        for m in dbs:
            t = m.get("text", "")
            if t and t not in picks:
                picks.append(t)
            if len(picks) >= top_k:
                break

    if not picks:
        picks = [select_relevant_quote(kws or ["ä»Š"])]

    st.session_state.setdefault("recent_maxims", [])
    for p in picks:
        if p and p not in st.session_state.recent_maxims:
            st.session_state.recent_maxims.append(p)
    st.session_state.recent_maxims = st.session_state.recent_maxims[-20:]

    return picks[:top_k]


def compose_poem_and_hint(picks: List[str], mood: Mood) -> Tuple[str, str]:
    season = random.choice(SEASONS)
    head = picks[0] if picks else "ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚"
    if len(head) > 30:
        head = head[:30] + "..."
    poem = f"{season}ï¼{head}"

    mood_scores = {
        "fatigue": mood.fatigue,
        "anxiety": mood.anxiety,
        "curiosity": mood.curiosity,
        "loneliness": mood.loneliness,
        "decisiveness": mood.decisiveness,
    }
    k, v = max(mood_scores.items(), key=lambda x: x[1])
    hints = NEXT_STEPS_BY_MOOD.get(k, NEXT_STEPS_BY_MOOD["default"]) if v > 0.3 else NEXT_STEPS_BY_MOOD["default"]
    return poem, random.choice(hints)


# -------------------------
# LLM + fallback (always show)
# -------------------------

@dataclass
class LLMResult:
    text: str
    ok: bool
    reason: str = ""
    status_code: Optional[int] = None
    headers: Optional[Dict[str, str]] = None


def _pick_rate_headers(headers: Dict[str, str]) -> Dict[str, str]:
    keep = {}
    for k, v in headers.items():
        kl = k.lower()
        if "ratelimit" in kl or kl in ("retry-after", "x-ratelimit-remaining", "x-ratelimit-limit"):
            keep[k] = v
    return keep


def build_omikuji_prompt(user_text: str, god: Dict, picks: List[str], mood: Mood) -> str:
    maxims = "\n".join([f"- {p}" for p in picks[:2]])
    return f"""ã‚ãªãŸã¯ã€{god.get('name','ç¥')}ã€ã¨ã—ã¦æ—¥æœ¬èªã§è©±ã—ã¾ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡˜ã„/æ‚©ã¿ï¼š
ã€Œ{user_text}ã€

å‚è€ƒæ ¼è¨€ï¼š
{maxims}

æ°—åˆ†ï¼šç–²ã‚Œ={mood.fatigue:.2f}, ä¸å®‰={mood.anxiety:.2f}, å¥½å¥‡å¿ƒ={mood.curiosity:.2f}, å­¤ç‹¬={mood.loneliness:.2f}, æ±ºæ–­={mood.decisiveness:.2f}

å‡ºåŠ›æ¡ä»¶ï¼š
- ãŠã¿ãã˜é¢¨
- 50ã€œ100æ–‡å­—
- ã‚„ã•ã—ãã€æœ€å¾Œã¯å‰å‘ãã«

ç¥è¨—ï¼š
"""


def hf_generate(prompt: str, model: str, api_key: str,
               max_new_tokens: int = 120, temperature: float = 0.7, top_p: float = 0.9,
               timeout: int = 30, retries: int = 2, backoff: float = 1.5) -> LLMResult:
    url = f"https://api-inference.huggingface.co/models/{model}"
    headers = {}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": int(max_new_tokens),
            "temperature": float(temperature),
            "top_p": float(top_p),
            "return_full_text": False,
        }
    }

    for attempt in range(retries + 1):
        try:
            r = requests.post(url, headers=headers, json=payload, timeout=timeout)
            hdrs = _pick_rate_headers(dict(r.headers))
            if r.status_code == 200:
                data = r.json()
                gen = ""
                if isinstance(data, list) and data:
                    gen = data[0].get("generated_text") or data[0].get("text") or ""
                elif isinstance(data, dict):
                    gen = data.get("generated_text") or data.get("text") or ""
                gen = (gen or "").strip()
                if gen:
                    return LLMResult(text=gen, ok=True, reason="ok", status_code=200, headers=hdrs)
                return LLMResult(text="", ok=False, reason="empty", status_code=200, headers=hdrs)

            if r.status_code in (429, 502, 503, 504):
                if attempt < retries:
                    time.sleep(backoff ** attempt)
                    continue
                return LLMResult(text="", ok=False, reason="busy_or_rate_limited", status_code=r.status_code, headers=hdrs)

            if r.status_code in (401, 403):
                return LLMResult(text="", ok=False, reason="auth_error", status_code=r.status_code, headers=hdrs)

            return LLMResult(text="", ok=False, reason="http_error", status_code=r.status_code, headers=hdrs)

        except Exception as e:
            if attempt < retries:
                time.sleep(backoff ** attempt)
                continue
            return LLMResult(text="", ok=False, reason=f"exception:{type(e).__name__}")

    return LLMResult(text="", ok=False, reason="unknown")


def fallback_short_oracle(user_text: str, god: Dict, picks: List[str], mood: Mood) -> str:
    kws = extract_keywords(user_text, top_n=6)
    core = picks[0] if picks else (god.get("maxim") or "ä»Šã‚’å¤§åˆ‡ã«")

    mood_scores = {"ç–²ã‚Œ": mood.fatigue, "ä¸å®‰": mood.anxiety, "å¥½å¥‡å¿ƒ": mood.curiosity, "å­¤ç‹¬": mood.loneliness, "æ±ºæ–­": mood.decisiveness}
    main_mood = max(mood_scores.items(), key=lambda x: x[1])[0]

    templates = [
        "{main}ã®æ°—é…ãŒå¼·ã„ã€‚{kw}ã‚’ä¸€ã¤ã ã‘å®ˆã‚Šã€{end}ã€‚",
        "{kw}ã«ç›®ã‚’å‘ã‘ã‚ˆã€‚{core}ã€‚{end}",
        "ç„¦ã‚‰ãšã€{kw}ã‚’æ•´ãˆã‚ˆã€‚{core}ã€‚{end}",
        "{main}ã®æ™‚ã¯å°ã•ãã€‚{kw}ã‹ã‚‰å§‹ã‚ã‚ˆã€‚{end}",
    ]

    kw = random.choice(kws) if kws else random.choice(GLOBAL_WORDS_DATABASE)
    ending = random.choice(["ä»Šæ—¥ã®ä¸€æ­©ã¯å¿…ãšå®Ÿã‚‹ã€‚", "å¤§ä¸ˆå¤«ã€é“ã¯ç¶šã„ã¦ã„ã‚‹ã€‚", "ç¸ã¯é™ã‹ã«çµã°ã‚Œã‚‹ã€‚", "ã‚ãªãŸã®è¦³æ¸¬ãŒã€ä¸–ç•Œç·šã‚’æ•´ãˆã‚‹ã€‚"])

    text = random.choice(templates).format(main=main_mood, kw=kw, core=core, end=ending)
    if len(text) > 110:
        text = text[:108] + "â€¦"
    return text


def explain_llm_issue(meta: Dict) -> str:
    provider = meta.get("provider")
    status = meta.get("status")
    reason = meta.get("reason", "")
    if provider == "huggingface":
        if status == 429:
            return "æ¨å®šåŸå› ï¼šãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆç„¡æ–™æ /æ··é›‘/çŸ­æ™‚é–“ã®é›†ä¸­ã‚¢ã‚¯ã‚»ã‚¹ï¼‰ã€‚"
        if status in (502, 503, 504):
            return "æ¨å®šåŸå› ï¼šHugging Faceå´ã®æ··é›‘/ä¸€æ™‚éšœå®³ã€‚"
        if status in (401, 403):
            return "æ¨å®šåŸå› ï¼šAPIã‚­ãƒ¼æœªè¨­å®š/æ¨©é™ä¸è¶³ã€‚"
        if reason == "empty":
            return "æ¨å®šåŸå› ï¼š200ã ãŒç”Ÿæˆæ–‡ãŒç©ºï¼ˆãƒ¢ãƒ‡ãƒ«/å¿œç­”å½¢å¼ã®ç›¸æ€§ï¼‰ã€‚"
        return f"æ¨å®šåŸå› ï¼šHTTP {status} / {reason}"
    return f"æ¨å®šåŸå› ï¼š{reason}"


def generate_short_oracle_always(user_text: str, god: Dict, picks: List[str], mood: Mood,
                                llm_enabled: bool, hf_model: str,
                                hf_max_new_tokens: int, hf_temperature: float, hf_top_p: float) -> Tuple[str, Dict]:
    meta = {
        "provider": "huggingface",
        "llm_ok": False,
        "reason": "",
        "status": None,
        "headers": {},
        "fallback": False,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "model": hf_model,
    }

    api_key = get_hf_api_key()
    if llm_enabled and user_text.strip():
        prompt = build_omikuji_prompt(user_text, god, picks, mood)
        res = hf_generate(prompt, model=hf_model, api_key=api_key,
                          max_new_tokens=hf_max_new_tokens,
                          temperature=hf_temperature,
                          top_p=hf_top_p)
        meta.update({"llm_ok": bool(res.ok and (res.text or "").strip()), "reason": res.reason, "status": res.status_code, "headers": res.headers or {}})
        if meta["llm_ok"]:
            return res.text.strip(), meta

    meta["fallback"] = True
    return fallback_short_oracle(user_text, god, picks, mood), meta


# -------------------------
# Word sphere
# -------------------------

def calculate_energy_between_words(word1: str, word2: str) -> float:
    energy = 0.0
    common = set(word1) & set(word2)
    if common:
        energy -= len(common) * 0.25
    energy += float(_rng().normal(0, 0.12))
    return energy


def build_word_network(center_words: List[str], database: List[str], n_neighbors: int = 20) -> Dict:
    all_words = list(set(center_words + database))
    energies: Dict[str, float] = {}

    for w in all_words:
        if w in center_words:
            e = -2.0
        else:
            es = [calculate_energy_between_words(cw, w) for cw in center_words]
            e = float(np.mean(es) + _rng().normal(0, 0.08))
        energies[w] = e

    sorted_words = sorted(energies.items(), key=lambda x: (x[1], float(_rng().random())))
    selected = center_words.copy()
    for w, _e in sorted_words:
        if w not in selected and len(selected) < n_neighbors:
            selected.append(w)

    edges = []
    for i in range(len(selected)):
        for j in range(i + 1, len(selected)):
            e = calculate_energy_between_words(selected[i], selected[j])
            if e < -0.25:
                edges.append((i, j, e))

    return {"words": selected, "energies": {w: energies[w] for w in selected}, "edges": edges}


def place_words_on_sphere(n_words: int, center_indices: List[int]) -> np.ndarray:
    pos = np.zeros((n_words, 3))
    golden = np.pi * (3 - np.sqrt(5))
    for i in range(n_words):
        r = 0.35 + float(_rng().random()) * 0.15 if i in center_indices else 0.85 + float(_rng().random()) * 0.35
        theta = golden * i
        y = 1 - (i / float(max(1, n_words - 1))) * 2
        rad = math.sqrt(max(1e-9, 1 - y * y))
        x = math.cos(theta) * rad * r
        z = math.sin(theta) * rad * r
        pos[i] = [x, y, z]
    return pos


def create_3d_network_plot(network: Dict, positions: np.ndarray, center_indices: List[int]) -> go.Figure:
    fig = go.Figure()

    for i, j, e in network["edges"]:
        fig.add_trace(go.Scatter3d(
            x=[positions[i, 0], positions[j, 0]],
            y=[positions[i, 1], positions[j, 1]],
            z=[positions[i, 2], positions[j, 2]],
            mode="lines",
            line=dict(color="#4a9eff" if e < -0.5 else "#ff6b6b", width=0.6 + abs(e) * 1.6),
            showlegend=False,
            hoverinfo="skip",
        ))

    for i, w in enumerate(network["words"]):
        is_center = i in center_indices
        fig.add_trace(go.Scatter3d(
            x=[positions[i, 0]],
            y=[positions[i, 1]],
            z=[positions[i, 2]],
            mode="markers+text",
            marker=dict(
                size=14 if is_center else 8,
                color="#ffd700" if is_center else "#ffffff",
                line=dict(width=2, color="white"),
                opacity=0.9 if is_center else 0.65,
            ),
            text=[w],
            textposition="middle center",
            textfont=dict(size=20 if is_center else 16, color="#ffd700" if is_center else "#ffffff"),
            hovertemplate=f"<b>{w}</b><br>ã‚¨ãƒãƒ«ã‚®ãƒ¼: {network['energies'].get(w,0):.2f}<extra></extra>",
            showlegend=False,
        ))

    fig.update_layout(
        title=dict(text="è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“ï¼ˆQuantum Word Sphereï¼‰", x=0.5, xanchor="center"),
        scene=dict(
            xaxis=dict(showgrid=False, showticklabels=False, title=""),
            yaxis=dict(showgrid=False, showticklabels=False, title=""),
            zaxis=dict(showgrid=False, showticklabels=False, title=""),
            bgcolor="#0a0a1a",
        ),
        plot_bgcolor="#0a0a1a",
        paper_bgcolor="#0a0a1a",
        margin=dict(l=0, r=0, t=50, b=0),
        height=650,
    )

    return fig


# -------------------------
# Sidebar diagnostic panel
# -------------------------

def sidebar_diagnostic_panel():
    with st.sidebar.expander("ğŸ›  è¨ºæ–­æƒ…å ±ï¼ˆé–‹ç™ºè€…å‘ã‘ï¼‰", expanded=False):
        meta = st.session_state.get("last_llm_meta")
        if not meta:
            st.caption("ã¾ã è¨ºæ–­æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“")
            return
        st.write(explain_llm_issue(meta))
        st.json(meta)
        st.download_button(
            "è¨ºæ–­æƒ…å ±ã‚’JSONã§ä¿å­˜",
            data=json.dumps(meta, ensure_ascii=False, indent=2),
            file_name="llm_diagnostic.json",
            mime="application/json",
        )


# -------------------------
# Main UI
# -------------------------

def main():
    st.title("ğŸ”® Q-Quest é‡å­ç¥è¨—ï¼ˆç”»åƒè¡¨ç¤ºï¼‹ç¥å›ºå®šï¼‹è¨ºæ–­ï¼‰")
    st.caption("12ç¥ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã§ä¸–ç•Œç·šã‚’å›ºå®šã—ã€QUBOæœ€é©åŒ–ã¨ç¥è¨—ã‚’è¡¨ç¤ºã—ã¾ã™")
    st.markdown("---")

    gods = LOADED_GODS if LOADED_GODS else TWELVE_GODS
    options = [f"{g.get('emoji','ğŸ”®')} {g.get('name','')}" for g in gods]

    # Sidebar: survey
    st.sidebar.header("ğŸ—³ï¸ ç›´è¦³ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆï¼ˆå¿…é ˆï¼‰")
    idx0 = int(st.session_state.get("selected_god_index", 0))
    idx0 = min(max(idx0, 0), len(options) - 1)
    selected_label = st.sidebar.radio("ã¾ãšç¥ã‚’é¸ã‚“ã§ãã ã•ã„", options, index=idx0)
    fixed_god_id = options.index(selected_label)
    st.session_state.selected_god_index = fixed_god_id

    # Show image in sidebar
    img = get_character_image_path(fixed_god_id)
    if img:
        st.sidebar.image(img, caption=options[fixed_god_id], use_container_width=True)

    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“Š è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä»»æ„ï¼‰")
    with st.sidebar.expander("Excelè¨­å®šã‚’èª­ã¿è¾¼ã‚€ï¼ˆk/lå¿…é ˆï¼‰", expanded=False):
        character_file = st.file_uploader("1) 12ç¥åŸºæœ¬æƒ…å ±", type=["xlsx", "xls"], key="char")
        maxim_file = st.file_uploader("2) æ ¼è¨€DBï¼ˆä»»æ„ï¼‰", type=["xlsx", "xls"], key="maxim")
        sense_to_vow_file = st.file_uploader("3) sense_to_vowï¼ˆä»»æ„ï¼‰", type=["xlsx", "xls"], key="sv")
        k_file = st.file_uploader("4) kè¡Œåˆ—ï¼ˆå¿…é ˆï¼‰", type=["xlsx", "xls"], key="k")
        l_file = st.file_uploader("5) lè¡Œåˆ—ï¼ˆå¿…é ˆï¼‰", type=["xlsx", "xls"], key="l")
        if st.button("èª­ã¿è¾¼ã¿", use_container_width=True):
            ok = load_excel_config(character_file, maxim_file, sense_to_vow_file, k_file, l_file)
            st.sidebar.success("âœ… èª­ã¿è¾¼ã¿å®Œäº†" if ok else "âŒ èª­ã¿è¾¼ã¿å¤±æ•—")
            st.rerun()

    # Sidebar: LLM settings (no key shown)
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¤– çŸ­æ–‡ç”Ÿæˆï¼ˆæ¯å›å¿…ãšè¡¨ç¤ºï¼‰")
    llm_enabled = st.sidebar.checkbox("Hugging Faceã§ç”Ÿæˆã‚’è©¦ã™", value=True)
    hf_model = st.sidebar.text_input("ãƒ¢ãƒ‡ãƒ«å", value="microsoft/DialoGPT-medium")
    hf_max_new_tokens = st.sidebar.slider("æœ€å¤§ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³", 60, 180, 120, 10)
    hf_temperature = st.sidebar.slider("temperature", 0.1, 1.2, 0.7, 0.1)
    hf_top_p = st.sidebar.slider("top_p", 0.1, 1.0, 0.9, 0.05)
    st.sidebar.caption("APIã‚­ãƒ¼ã¯ st.secrets / ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ï¼ˆUIã«ã¯è¡¨ç¤ºã—ã¾ã›ã‚“ï¼‰ã€‚")

    # Sidebar: optuna
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ“ˆ Optunaï¼ˆé€²æ—å¯è¦–åŒ–ï¼‰")
    run_optuna = st.sidebar.checkbox("Optunaã‚’å®Ÿè¡Œ", value=True, disabled=not OPTUNA_AVAILABLE)
    n_trials = st.sidebar.slider("è©¦è¡Œå›æ•°", 30, 200, 80, 10)
    if not OPTUNA_AVAILABLE:
        st.sidebar.info("optunaæœªå°å…¥ï¼šrequirements.txtã« optuna ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")

    # Sidebar: mode
    st.sidebar.markdown("---")
    mode = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰", ["å¯¾è©±å‹é‡å­ç¥è¨—", "è¨€è‘‰ã®çƒä½“å¯è¦–åŒ–"])

    sidebar_diagnostic_panel()

    if mode == "è¨€è‘‰ã®çƒä½“å¯è¦–åŒ–":
        st.header("ğŸª è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“")
        user_input = st.text_input("é¡˜ã„ã‚’å…¥åŠ›", value="ä¸–ç•Œå¹³å’Œã«è²¢çŒ®ã§ãã‚‹äººé–“ã«ãªã‚‹")
        if st.button("å¯è¦–åŒ–", use_container_width=True):
            kws = extract_keywords(user_input, top_n=8)
            if not kws:
                st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return
            net = build_word_network(kws, GLOBAL_WORDS_DATABASE, n_neighbors=20)
            centers = [i for i, w in enumerate(net["words"]) if w in kws]
            pos = place_words_on_sphere(len(net["words"]), centers)
            fig = create_3d_network_plot(net, pos, centers)
            st.plotly_chart(fig, use_container_width=True)
        return

# Main: oracle
    st.header("ğŸ”® é‡å­ç¥è¨—")
    st.caption(f"å›ºå®šã•ã‚ŒãŸç¥ï¼š{options[fixed_god_id]}")

    god = (LOADED_GODS if LOADED_GODS else TWELVE_GODS)[fixed_god_id]
    img_main = get_character_image_path(fixed_god_id)
    if img_main:
        st.image(img_main, width=320)

    user_text = st.text_area("ä»Šæ—¥ã®é¡˜ã„ãƒ»æ°—æŒã¡ã‚’ä¸€æ–‡ã§", placeholder="ä¾‹ï¼šç–²ã‚Œã¦ã„ã¦æ±ºæ–­ãŒã§ããªã„â€¦", height=120)

    if st.button("ç¥è¨—ã‚’æ±‚ã‚ã‚‹", type="primary", use_container_width=True):
        if not user_text.strip():
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return

        mood = infer_mood(user_text)
        st.session_state["last_mood"] = mood
        c1, c2, c3, c4, c5 = st.columns(5)
        c1.metric("ç–²ã‚Œ", f"{mood.fatigue:.2f}")
        c2.metric("ä¸å®‰", f"{mood.anxiety:.2f}")
        c3.metric("å¥½å¥‡å¿ƒ", f"{mood.curiosity:.2f}")
        c4.metric("å­¤ç‹¬", f"{mood.loneliness:.2f}")
        c5.metric("æ±ºæ–­", f"{mood.decisiveness:.2f}")

        # æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        x_cont = mood_to_sensation_vector(mood, binary=False, scale=5.0)
        x_bin = (x_cont >= 1.5).astype(float)

        # K/Lè¡Œåˆ—æº–å‚™
        gods_list = LOADED_GODS if LOADED_GODS else TWELVE_GODS
        k_matrix = K_MATRIX
        l_matrix = L_MATRIX

        if k_matrix is None:
            k_matrix = np.zeros((12, 12))
            for k, god_temp in enumerate(gods_list):
                for j in range(12):
                    k_matrix[k, j] = float(god_temp["vows"][f"vow{j+1:02d}"])

        if l_matrix is None:
            l_matrix = np.zeros((12, 4))
            roles = ["stillness", "flow", "ma", "sincerity"]
            for k, god_temp in enumerate(gods_list):
                for j, rn in enumerate(roles):
                    l_matrix[k, j] = float(god_temp["roles"][rn])

        # â˜…QUBOæ§‹ç¯‰ï¼ˆé‡å­æºã‚‰ãä»˜ãï¼‰
        Q, metadata = build_qubo_with_quantum_fluctuation(
            x_bin=x_bin,
            mood=mood,
            K_MATRIX=k_matrix,
            L_MATRIX=l_matrix,
            SENSE_TO_VOW_MATRIX=SENSE_TO_VOW_MATRIX,
            quantum_noise_level=0.6
        )

        # â˜…â˜…â˜… é‡å­çš„æºã‚‰ãã®å¯è¦–åŒ– â˜…â˜…â˜…
        with st.expander("ğŸŒ€ é‡å­çš„æºã‚‰ãã®è©³ç´°ï¼ˆã“ã®ç¬é–“ã ã‘ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ï¼‰", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("é‡å­ã‚·ãƒ¼ãƒ‰", f"{metadata['quantum_seed']}", 
                         help="ã“ã®ç¬é–“ã®å®‡å®™ã®çŠ¶æ…‹ã‚’è¡¨ã™æ•°å€¤ï¼ˆçœŸæ­£ä¹±æ•°ï¼‰")
                st.metric("ãƒã‚¤ã‚ºæ³¨å…¥ç®‡æ‰€", f"{len(metadata['noise_injections'])}ãƒ“ãƒƒãƒˆ",
                         help="QUBOã«æ³¨å…¥ã•ã‚ŒãŸé‡å­çš„æºã‚‰ãã®æ•°")
            
            with col2:
                st.metric("ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰å‹•ç®‡æ‰€", f"{len(metadata['energy_shifts'])}",
                         help="ç¥ã¨èª“é¡˜ã®çµã³ã¤ããŒé‡å­çš„ã«å¤‰åŒ–ã—ãŸç®‡æ‰€")
                
                shifts = list(metadata['energy_shifts'].values())
                if shifts:
                    avg_shift = np.mean(np.abs(shifts))
                    st.metric("å¹³å‡æºã‚‰ãå¼·åº¦", f"{avg_shift:.4f}",
                             help="ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å¤‰å‹•å¹…ï¼ˆå¤§ãã„ã»ã©æ„å¤–ãªçµæœã‚‚ï¼‰")
            
            if shifts:
                st.markdown("#### ã‚¨ãƒãƒ«ã‚®ãƒ¼æºã‚‰ãã®åˆ†å¸ƒ")
                fig_shift = px.histogram(
                    shifts, 
                    nbins=30, 
                    title="é‡å­çš„ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚·ãƒ•ãƒˆï¼ˆã“ã®ç¬é–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªåˆ†å¸ƒï¼‰",
                    labels={'value': 'ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰åŒ–é‡', 'count': 'é »åº¦'}
                )
                fig_shift.update_layout(showlegend=False, height=300)
                st.plotly_chart(fig_shift, use_container_width=True)
                
                st.caption("ğŸ’¡ ã“ã®åˆ†å¸ƒã¯æ¯å›ç•°ãªã‚Šã¾ã™ã€‚åŒã˜é¡˜ã„ã§ã‚‚ã€é‡å­çš„ãªæºã‚‰ãã«ã‚ˆã‚ŠçµæœãŒå¤‰ã‚ã‚Šã¾ã™ã€‚")

        # Optuna progress
        if run_optuna and OPTUNA_AVAILABLE:
            st.subheader("ğŸ“ˆ Optunaæœ€é©åŒ–ï¼ˆé€²æ—ï¼‰")
            container = st.empty()
            study = solve_optuna_fixed_char(Q, fixed_god_id=fixed_god_id, n_trials=n_trials, progress_container=container)
            if study is not None:
                with st.expander("Optunaå¯è¦–åŒ–", expanded=False):
                    tabs = st.tabs(["å±¥æ­´", "é‡è¦åº¦", "ãƒ‘ãƒ©ãƒ¬ãƒ«", "ç­‰é«˜ç·š", "ã‚¹ãƒ©ã‚¤ã‚¹", "ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³"])
                    try:
                        with tabs[0]:
                            st.plotly_chart(plot_optimization_history(study), use_container_width=True)
                        with tabs[1]:
                            st.plotly_chart(plot_param_importances(study), use_container_width=True)
                        with tabs[2]:
                            st.plotly_chart(plot_parallel_coordinate(study), use_container_width=True)
                        with tabs[3]:
                            params = list(study.best_params.keys())
                            if len(params) >= 2:
                                st.plotly_chart(plot_contour(study, params=[params[0], params[1]]), use_container_width=True)
                            else:
                                st.info("ç­‰é«˜ç·šè¡¨ç¤ºã«ã¯2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥ä¸ŠãŒå¿…è¦ã§ã™")
                        with tabs[4]:
                            st.plotly_chart(plot_slice(study), use_container_width=True)
                        with tabs[5]:
                            st.plotly_chart(plot_timeline(study), use_container_width=True)
                    except Exception as e:
                        st.warning(f"Optunaå¯è¦–åŒ–ã®ä¸€éƒ¨ã«å¤±æ•—: {e}")

        # exact landscapeï¼ˆâ˜…å…¨ç¥å¯¾è±¡ã«å¤‰æ›´â˜…ï¼‰
        sols = solve_exact_all_gods(Q)
        topN = 20
        energies = [e for e, _ in sols[:topN]]
        st.subheader("ğŸ—ºï¸ ã‚¨ãƒãƒ«ã‚®ãƒ¼åœ°å½¢ï¼ˆä¸Šä½å€™è£œãƒ»â˜…å…¨12ç¥ãŒå¯¾è±¡â˜…ï¼‰")
        fig_bar = px.bar(x=[f"å€™è£œ{i+1}" for i in range(topN)], y=energies,
                         labels={"x": "å€™è£œ", "y": "ã‚¨ãƒãƒ«ã‚®ãƒ¼"},
                         title="Energy landscapeï¼ˆä½ã„ã»ã©ç¸ãŒçµã°ã‚Œã‚„ã™ã„ï¼‰")
        fig_bar.update_xaxes(tickangle=-60)
        st.plotly_chart(fig_bar, use_container_width=True)

        # â˜…Boltzmann samplingï¼ˆé‡å­çš„ç¢ºç‡é¸æŠï¼‰
        pool = sols[:20]
        T = calculate_quantum_temperature(mood)

        st.write(f"**é‡å­æ¸©åº¦ï¼ˆæºã‚‰ãã®å¼·ã•ï¼‰**: {T:.3f}")
        st.caption("æ¸©åº¦ãŒé«˜ã„ã»ã©å¤šæ§˜ãªé¸æŠã€ä½ã„ã»ã©æœ€é©è§£ã«é›†ä¸­")

        e_pick, x_pick = boltzmann_sample(pool, temperature=T, use_quantum_random=True)

        # é¸ã°ã‚ŒãŸç¥ã‚’ç‰¹å®š
        c_start = 20
        selected_god_id = int(np.argmax(x_pick[c_start:c_start+12]))
        god = (LOADED_GODS if LOADED_GODS else TWELVE_GODS)[selected_god_id]
        
        # picks / short oracle
        picks = select_picks_for_god(god, user_text, top_k=3)
        poem, hint = compose_poem_and_hint(picks, mood)
        short_text, meta = generate_short_oracle_always(user_text, god, picks, mood,
                                                        llm_enabled, hf_model,
                                                        hf_max_new_tokens, hf_temperature, hf_top_p)
        st.session_state["last_llm_meta"] = meta

        st.markdown("---")
        st.subheader(f"ğŸ´ {god['emoji']} {god['name']} ã‹ã‚‰ã®ç¥è¨—")
        st.write(f"**é¸ã°ã‚ŒãŸç¥**: {god['name']} ({god['name_en']})")
        st.write(f"**ã‚¨ãƒãƒ«ã‚®ãƒ¼**: {e_pick:.3f} / **æ¸©åº¦**: {T:.3f}")

        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒè¡¨ç¤º
        img = get_character_image_path(selected_god_id)
        if img:
            st.image(img, width=320)
            
        st.markdown("### âœ¨ ç¥è¨—ï¼ˆçŸ­æ–‡ï¼‰")
        st.success(short_text)

        st.markdown("### ğŸ“œ é¸ã°ã‚ŒãŸç¸ï¼ˆæ ¼è¨€ï¼‰")
        for p in picks:
            src = get_maxim_source(p)
            st.markdown(f"- **{p}** *(å‡ºå…¸: {src['source']})*")

        st.markdown(f"### ğŸƒ ã“ã¨ã°ï¼ˆçŸ­å¥ï¼‰\nã€Œ{poem}ã€")
        st.markdown(f"### ğŸ‘£ æ¬¡ã®ä¸€æ­©\n{hint}")

        st.markdown("---")
        st.subheader("ğŸª ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“ï¼ˆè£œåŠ©å¯è¦–åŒ–ï¼‰")
        kws = extract_keywords(user_text, top_n=8)
        if kws:
            st.caption("æŠ½å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: " + ", ".join(kws))
            net = build_word_network(kws, GLOBAL_WORDS_DATABASE, n_neighbors=20)
            centers = [i for i, w in enumerate(net["words"]) if w in kws]
            pos = place_words_on_sphere(len(net["words"]), centers)
            fig = create_3d_network_plot(net, pos, centers)
            st.plotly_chart(fig, use_container_width=True)


if __name__ == "__main__":
    main()